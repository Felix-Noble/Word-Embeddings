{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07fdac22-043e-4613-b3f0-b9441d3d10f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "from M_Pipeline import Mpipe\n",
    "\n",
    "root = \"Path\\\\To\\\\Root\"\n",
    "root = r\"E:\\Dropbox\\2. Cognitive science\\Music evoked autobiographical memories\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d0a9b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mpipe initialised.\n",
      "loaded data from: E:\\Dropbox\\2. Cognitive science\\Music evoked autobiographical memories\\data\\spotify_playlists_data.csv\n",
      "\n",
      "-Type: <class 'pandas.core.frame.DataFrame'>\n",
      "-Shape:(10809, 2)\n",
      "- -Obervations: 10809\n",
      "- -Features/measures: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe = Mpipe(root, \"data\\\\spotify_playlists_data.csv\", \"data\\\\SBERT\\\\playlists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1afedfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Song-Artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Songs compiled by EMI from their label, showca...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New, leftfield, and for the real alternative s...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10804</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10805</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10806</th>\n",
       "      <td>Similar tracks to Trance (with Travis Scott &amp;a...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10807</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10808</th>\n",
       "      <td>We pulled out the feathers for this type of we...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10809 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Descriptions  Song-Artist\n",
       "0      Songs compiled by EMI from their label, showca...          NaN\n",
       "1                                                    NaN          NaN\n",
       "2      New, leftfield, and for the real alternative s...          NaN\n",
       "3                                                    NaN          NaN\n",
       "4                                                    NaN          NaN\n",
       "...                                                  ...          ...\n",
       "10804                                                NaN          NaN\n",
       "10805                                                NaN          NaN\n",
       "10806  Similar tracks to Trance (with Travis Scott &a...          NaN\n",
       "10807                                                NaN          NaN\n",
       "10808  We pulled out the feathers for this type of we...          NaN\n",
       "\n",
       "[10809 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a3e12db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning text data\n",
    "\n",
    "for i in range(0,len(pipe.data.values)):\n",
    "    temp = pipe.data.iloc[i, 0]\n",
    "    if type(temp) == str:\n",
    "        # print(temp)\n",
    "        temp = temp.lower()\n",
    "        temp = temp.translate(str.maketrans('', '', string.punctuation))\n",
    "        temp = temp.translate(str.maketrans('', '', string.digits))\n",
    "        temp = temp.replace(\"(\",\"\")\n",
    "        temp = temp.replace(\")\",\"\")\n",
    "\n",
    "        temp = \" \".join(temp.split())\n",
    "        # edit the orignal value in place \n",
    "        pipe.data.iloc[i,0] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e993fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Descriptions</th>\n",
       "      <th>Song-Artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>songs compiled by emi from their label showcas...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new leftfield and for the real alternative stans</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10804</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10805</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10806</th>\n",
       "      <td>similar tracks to trance with travis scott amp...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10807</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10808</th>\n",
       "      <td>we pulled out the feathers for this type of we...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10809 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Descriptions  Song-Artist\n",
       "0      songs compiled by emi from their label showcas...          NaN\n",
       "1                                                    NaN          NaN\n",
       "2       new leftfield and for the real alternative stans          NaN\n",
       "3                                                    NaN          NaN\n",
       "4                                                    NaN          NaN\n",
       "...                                                  ...          ...\n",
       "10804                                                NaN          NaN\n",
       "10805                                                NaN          NaN\n",
       "10806  similar tracks to trance with travis scott amp...          NaN\n",
       "10807                                                NaN          NaN\n",
       "10808  we pulled out the feathers for this type of we...          NaN\n",
       "\n",
       "[10809 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect after cleaning\n",
    "pipe.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1668f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Type: <class 'pandas.core.frame.DataFrame'>\n",
      "-Shape:(10809, 2)\n",
      "- -Obervations: 10809\n",
      "- -Features/measures: 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative method for data inspection\n",
    "pipe.descr_data(pipe.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "345bf98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Dropbox\\2. Cognitive science\\Music evoked autobiographical memories\\code\\M_Pipeline.py:108: UserWarning: \n",
      "----- WARNING -----\n",
      "[pandas.DataFrame] expected, got [Series].\n",
      "Attempting conversion to pd.DataFrame.\n",
      "Conversion Successful\n",
      "---\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create Mini LM-L6-v2 embeddings \u001b[39;00m\n\u001b[32m      2\u001b[39m sbert_args = {\u001b[33m\"\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mall-MiniLM-L6-v2\u001b[39m\u001b[33m\"\u001b[39m}\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m embed = \u001b[43mpipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSBERT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDescriptions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msbert_args\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# pass only text to the SBERT method \u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Dropbox\\2. Cognitive science\\Music evoked autobiographical memories\\code\\M_Pipeline.py:159\u001b[39m, in \u001b[36mM_embed.SBERT\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    154\u001b[39m model = SentenceTransformer(model_name_or_path=\u001b[38;5;28mself\u001b[39m.step_params[\u001b[33m\"\u001b[39m\u001b[33mmodel_name\u001b[39m\u001b[33m\"\u001b[39m])\u001b[38;5;66;03m# initialist SBERT model\u001b[39;00m\n\u001b[32m    155\u001b[39m \u001b[38;5;66;03m# if self.safe_run: # make sure model has attributes assigned to it (from the step attributes list)\u001b[39;00m\n\u001b[32m    156\u001b[39m \u001b[38;5;66;03m#     self.check_attr(model, self.step_params)\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;66;03m# model.__dict__.update(self.step_params) # update model perameters \u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m embeddings = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_to_numpy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# transform text to embeddings \u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# return df containing embeddings (n_observations, n_features)\u001b[39;00m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m embeddings.shape[\u001b[32m0\u001b[39m]<\u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:685\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[39m\n\u001b[32m    682\u001b[39m features.update(extra_features)\n\u001b[32m    684\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m685\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    686\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    687\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:758\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m    756\u001b[39m     module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m    757\u001b[39m     module_kwargs = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[32m--> \u001b[39m\u001b[32m758\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:442\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    435\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns token_embeddings, cls_token\"\"\"\u001b[39;00m\n\u001b[32m    436\u001b[39m trans_features = {\n\u001b[32m    437\u001b[39m     key: value\n\u001b[32m    438\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items()\n\u001b[32m    439\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33minput_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mattention_mask\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mtoken_type_ids\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33minputs_embeds\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    440\u001b[39m }\n\u001b[32m--> \u001b[39m\u001b[32m442\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    443\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    444\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1016\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1009\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m   1010\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m   1011\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m   1012\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m   1013\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m   1014\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1016\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1017\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1026\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1027\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1028\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1029\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:662\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    651\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    652\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    653\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    659\u001b[39m         output_attentions,\n\u001b[32m    660\u001b[39m     )\n\u001b[32m    661\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m662\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    666\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    667\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    672\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    673\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:594\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    591\u001b[39m     cross_attn_present_key_value = cross_attention_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    592\u001b[39m     present_key_value = present_key_value + cross_attn_present_key_value\n\u001b[32m--> \u001b[39m\u001b[32m594\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    595\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    596\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    597\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    599\u001b[39m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\transformers\\pytorch_utils.py:253\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:607\u001b[39m, in \u001b[36mBertLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m    606\u001b[39m     intermediate_output = \u001b[38;5;28mself\u001b[39m.intermediate(attention_output)\n\u001b[32m--> \u001b[39m\u001b[32m607\u001b[39m     layer_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mintermediate_output\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    608\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:519\u001b[39m, in \u001b[36mBertOutput.forward\u001b[39m\u001b[34m(self, hidden_states, input_tensor)\u001b[39m\n\u001b[32m    518\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor, input_tensor: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    520\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.dropout(hidden_states)\n\u001b[32m    521\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.LayerNorm(hidden_states + input_tensor)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\anaconda\\envs\\MEAMs_env\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Create Mini LM-L6-v2 embeddings \n",
    "sbert_args = {\"model_name\":\"all-MiniLM-L6-v2\"}\n",
    "embed = pipe.SBERT(pipe.data.loc[:,\"Descriptions\"], sbert_args) # pass only text to the SBERT method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a0ffe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>Feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_375</th>\n",
       "      <th>Feature_376</th>\n",
       "      <th>Feature_377</th>\n",
       "      <th>Feature_378</th>\n",
       "      <th>Feature_379</th>\n",
       "      <th>Feature_380</th>\n",
       "      <th>Feature_381</th>\n",
       "      <th>Feature_382</th>\n",
       "      <th>Feature_383</th>\n",
       "      <th>Feature_384</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017859</td>\n",
       "      <td>-0.052951</td>\n",
       "      <td>-0.011872</td>\n",
       "      <td>0.018726</td>\n",
       "      <td>0.121636</td>\n",
       "      <td>0.093625</td>\n",
       "      <td>0.035028</td>\n",
       "      <td>-0.043307</td>\n",
       "      <td>-0.004407</td>\n",
       "      <td>0.053573</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000988</td>\n",
       "      <td>-0.056807</td>\n",
       "      <td>0.017905</td>\n",
       "      <td>0.076707</td>\n",
       "      <td>-0.011841</td>\n",
       "      <td>0.032371</td>\n",
       "      <td>-0.001254</td>\n",
       "      <td>-0.053575</td>\n",
       "      <td>0.065018</td>\n",
       "      <td>-0.016335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.024098</td>\n",
       "      <td>-0.081167</td>\n",
       "      <td>-0.051373</td>\n",
       "      <td>-0.046404</td>\n",
       "      <td>0.078600</td>\n",
       "      <td>0.103969</td>\n",
       "      <td>0.017108</td>\n",
       "      <td>0.050106</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>-0.015987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026933</td>\n",
       "      <td>0.077149</td>\n",
       "      <td>-0.045351</td>\n",
       "      <td>0.056227</td>\n",
       "      <td>-0.052590</td>\n",
       "      <td>-0.040247</td>\n",
       "      <td>0.026185</td>\n",
       "      <td>-0.031578</td>\n",
       "      <td>0.006535</td>\n",
       "      <td>0.122273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.043237</td>\n",
       "      <td>0.094813</td>\n",
       "      <td>-0.010670</td>\n",
       "      <td>0.011476</td>\n",
       "      <td>0.027026</td>\n",
       "      <td>0.012613</td>\n",
       "      <td>0.082173</td>\n",
       "      <td>0.024508</td>\n",
       "      <td>0.062176</td>\n",
       "      <td>0.014488</td>\n",
       "      <td>...</td>\n",
       "      <td>0.037722</td>\n",
       "      <td>0.014578</td>\n",
       "      <td>0.014672</td>\n",
       "      <td>0.119747</td>\n",
       "      <td>-0.074584</td>\n",
       "      <td>0.018617</td>\n",
       "      <td>0.106803</td>\n",
       "      <td>0.013504</td>\n",
       "      <td>-0.052876</td>\n",
       "      <td>-0.066565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.039284</td>\n",
       "      <td>0.007996</td>\n",
       "      <td>-0.018762</td>\n",
       "      <td>0.007279</td>\n",
       "      <td>-0.015874</td>\n",
       "      <td>0.023828</td>\n",
       "      <td>0.085040</td>\n",
       "      <td>-0.052815</td>\n",
       "      <td>-0.035384</td>\n",
       "      <td>-0.056437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034542</td>\n",
       "      <td>-0.001568</td>\n",
       "      <td>-0.043522</td>\n",
       "      <td>0.047641</td>\n",
       "      <td>-0.078307</td>\n",
       "      <td>-0.007703</td>\n",
       "      <td>0.057669</td>\n",
       "      <td>-0.054547</td>\n",
       "      <td>0.040223</td>\n",
       "      <td>-0.027526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.045154</td>\n",
       "      <td>-0.139387</td>\n",
       "      <td>0.018474</td>\n",
       "      <td>0.052009</td>\n",
       "      <td>0.046936</td>\n",
       "      <td>0.037674</td>\n",
       "      <td>0.050982</td>\n",
       "      <td>-0.087449</td>\n",
       "      <td>-0.029200</td>\n",
       "      <td>-0.038586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.092351</td>\n",
       "      <td>0.082040</td>\n",
       "      <td>-0.040928</td>\n",
       "      <td>0.051098</td>\n",
       "      <td>0.041205</td>\n",
       "      <td>-0.007349</td>\n",
       "      <td>0.022972</td>\n",
       "      <td>-0.031780</td>\n",
       "      <td>-0.075105</td>\n",
       "      <td>0.016485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6427</th>\n",
       "      <td>-0.070549</td>\n",
       "      <td>-0.098141</td>\n",
       "      <td>0.039776</td>\n",
       "      <td>-0.039949</td>\n",
       "      <td>0.022926</td>\n",
       "      <td>0.091583</td>\n",
       "      <td>0.041688</td>\n",
       "      <td>-0.068232</td>\n",
       "      <td>0.017583</td>\n",
       "      <td>0.014638</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086614</td>\n",
       "      <td>0.022577</td>\n",
       "      <td>-0.089854</td>\n",
       "      <td>0.037627</td>\n",
       "      <td>-0.061235</td>\n",
       "      <td>0.061106</td>\n",
       "      <td>0.032804</td>\n",
       "      <td>-0.032824</td>\n",
       "      <td>0.019745</td>\n",
       "      <td>-0.010014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6428</th>\n",
       "      <td>-0.004636</td>\n",
       "      <td>-0.070509</td>\n",
       "      <td>0.103589</td>\n",
       "      <td>0.034032</td>\n",
       "      <td>0.016794</td>\n",
       "      <td>0.031171</td>\n",
       "      <td>0.131057</td>\n",
       "      <td>0.023853</td>\n",
       "      <td>-0.012816</td>\n",
       "      <td>-0.066850</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030895</td>\n",
       "      <td>-0.025194</td>\n",
       "      <td>-0.078362</td>\n",
       "      <td>0.004574</td>\n",
       "      <td>-0.013479</td>\n",
       "      <td>-0.015946</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.040595</td>\n",
       "      <td>-0.083447</td>\n",
       "      <td>-0.100151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6429</th>\n",
       "      <td>-0.074290</td>\n",
       "      <td>-0.085987</td>\n",
       "      <td>-0.031304</td>\n",
       "      <td>-0.054750</td>\n",
       "      <td>0.019203</td>\n",
       "      <td>0.127871</td>\n",
       "      <td>0.064893</td>\n",
       "      <td>0.004316</td>\n",
       "      <td>-0.084836</td>\n",
       "      <td>0.082225</td>\n",
       "      <td>...</td>\n",
       "      <td>0.041737</td>\n",
       "      <td>0.081827</td>\n",
       "      <td>-0.011076</td>\n",
       "      <td>-0.001045</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>-0.014998</td>\n",
       "      <td>-0.003726</td>\n",
       "      <td>0.042030</td>\n",
       "      <td>0.010248</td>\n",
       "      <td>0.172598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>-0.101344</td>\n",
       "      <td>-0.019642</td>\n",
       "      <td>-0.019496</td>\n",
       "      <td>-0.019772</td>\n",
       "      <td>0.034920</td>\n",
       "      <td>0.037360</td>\n",
       "      <td>0.118364</td>\n",
       "      <td>-0.129719</td>\n",
       "      <td>0.014642</td>\n",
       "      <td>-0.025143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132405</td>\n",
       "      <td>-0.003862</td>\n",
       "      <td>-0.094848</td>\n",
       "      <td>0.025994</td>\n",
       "      <td>-0.005379</td>\n",
       "      <td>0.022873</td>\n",
       "      <td>0.051107</td>\n",
       "      <td>0.002513</td>\n",
       "      <td>0.110482</td>\n",
       "      <td>-0.033491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6431</th>\n",
       "      <td>-0.052781</td>\n",
       "      <td>-0.093028</td>\n",
       "      <td>0.098729</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.012887</td>\n",
       "      <td>-0.007789</td>\n",
       "      <td>0.158994</td>\n",
       "      <td>0.001972</td>\n",
       "      <td>0.064123</td>\n",
       "      <td>-0.026426</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042027</td>\n",
       "      <td>-0.083490</td>\n",
       "      <td>-0.022438</td>\n",
       "      <td>-0.001167</td>\n",
       "      <td>0.037755</td>\n",
       "      <td>0.016201</td>\n",
       "      <td>-0.072254</td>\n",
       "      <td>-0.008608</td>\n",
       "      <td>-0.036708</td>\n",
       "      <td>-0.023996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6432 rows × 384 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0      0.017859  -0.052951  -0.011872   0.018726   0.121636   0.093625   \n",
       "1     -0.024098  -0.081167  -0.051373  -0.046404   0.078600   0.103969   \n",
       "2     -0.043237   0.094813  -0.010670   0.011476   0.027026   0.012613   \n",
       "3     -0.039284   0.007996  -0.018762   0.007279  -0.015874   0.023828   \n",
       "4     -0.045154  -0.139387   0.018474   0.052009   0.046936   0.037674   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "6427  -0.070549  -0.098141   0.039776  -0.039949   0.022926   0.091583   \n",
       "6428  -0.004636  -0.070509   0.103589   0.034032   0.016794   0.031171   \n",
       "6429  -0.074290  -0.085987  -0.031304  -0.054750   0.019203   0.127871   \n",
       "6430  -0.101344  -0.019642  -0.019496  -0.019772   0.034920   0.037360   \n",
       "6431  -0.052781  -0.093028   0.098729   0.003319   0.012887  -0.007789   \n",
       "\n",
       "      Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_375  \\\n",
       "0      0.035028  -0.043307  -0.004407    0.053573  ...     0.000988   \n",
       "1      0.017108   0.050106   0.022400   -0.015987  ...     0.026933   \n",
       "2      0.082173   0.024508   0.062176    0.014488  ...     0.037722   \n",
       "3      0.085040  -0.052815  -0.035384   -0.056437  ...     0.034542   \n",
       "4      0.050982  -0.087449  -0.029200   -0.038586  ...     0.092351   \n",
       "...         ...        ...        ...         ...  ...          ...   \n",
       "6427   0.041688  -0.068232   0.017583    0.014638  ...     0.086614   \n",
       "6428   0.131057   0.023853  -0.012816   -0.066850  ...     0.030895   \n",
       "6429   0.064893   0.004316  -0.084836    0.082225  ...     0.041737   \n",
       "6430   0.118364  -0.129719   0.014642   -0.025143  ...     0.132405   \n",
       "6431   0.158994   0.001972   0.064123   -0.026426  ...    -0.042027   \n",
       "\n",
       "      Feature_376  Feature_377  Feature_378  Feature_379  Feature_380  \\\n",
       "0       -0.056807     0.017905     0.076707    -0.011841     0.032371   \n",
       "1        0.077149    -0.045351     0.056227    -0.052590    -0.040247   \n",
       "2        0.014578     0.014672     0.119747    -0.074584     0.018617   \n",
       "3       -0.001568    -0.043522     0.047641    -0.078307    -0.007703   \n",
       "4        0.082040    -0.040928     0.051098     0.041205    -0.007349   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "6427     0.022577    -0.089854     0.037627    -0.061235     0.061106   \n",
       "6428    -0.025194    -0.078362     0.004574    -0.013479    -0.015946   \n",
       "6429     0.081827    -0.011076    -0.001045     0.015320    -0.014998   \n",
       "6430    -0.003862    -0.094848     0.025994    -0.005379     0.022873   \n",
       "6431    -0.083490    -0.022438    -0.001167     0.037755     0.016201   \n",
       "\n",
       "      Feature_381  Feature_382  Feature_383  Feature_384  \n",
       "0       -0.001254    -0.053575     0.065018    -0.016335  \n",
       "1        0.026185    -0.031578     0.006535     0.122273  \n",
       "2        0.106803     0.013504    -0.052876    -0.066565  \n",
       "3        0.057669    -0.054547     0.040223    -0.027526  \n",
       "4        0.022972    -0.031780    -0.075105     0.016485  \n",
       "...           ...          ...          ...          ...  \n",
       "6427     0.032804    -0.032824     0.019745    -0.010014  \n",
       "6428     0.003435     0.040595    -0.083447    -0.100151  \n",
       "6429    -0.003726     0.042030     0.010248     0.172598  \n",
       "6430     0.051107     0.002513     0.110482    -0.033491  \n",
       "6431    -0.072254    -0.008608    -0.036708    -0.023996  \n",
       "\n",
       "[6432 rows x 384 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect embeddings\n",
    "# pipe.SBERT automatically removed NaN rows, note the potential for differences in output n_observations (rows) than input\n",
    "embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041478c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame of shape (6432, 384) saved to E: ... \\playlists\\spotify_descriptions cleaned1 all-MiniLM-L6.csv\n"
     ]
    }
   ],
   "source": [
    "pipe.save(embed,\"spotify_descriptions all-MiniLM-L6\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
